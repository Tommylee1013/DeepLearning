'''
# Colab, jupyter notebook 환경에서 진행 시 아래 코드로 데이터 다운로드
!curl -L -s -o '/content/ESC-50-master-16k.tar' 'https://drive.google.com/uc?id=1hFt-qarD_Ihjb3jW7pd3tje2pcY5tfuJ&confirm=t'
!tar -xvf "ESC-50-master-16k.tar"
'''

from torch.utils.data import Dataset, TensorDataset, DataLoader
import torch
import torch.nn as nn
import torch.nn.functional as F
import librosa

import numpy as np
import pandas as pd

from glob import glob


# Device Configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load ESC-50 Data & Preprocess
metadata = pd.read_csv("./ESC-50-master-16k/meta/esc50.csv")
wav_list = sorted(glob("./ESC-50-master-16k/resample/*.wav"))
def spec_to_image(spec, eps=1e-6):
    mean = spec.mean()
    std = spec.std()
    spec_norm = (spec - mean) / (std + eps)
    spec_min, spec_max = spec_norm.min(), spec_norm.max()
    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)
    spec_scaled = spec_scaled.astype(np.uint8)
    return spec_scaled

class esc50dataset(Dataset):
    def __init__(self, wavlist, metadata):
        self.labels = np.array(metadata.target).astype(int)
        self.audio = []
        for f in wavlist:
            wav, sr = librosa.load(f, sr=None)
            spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=1024, hop_length=640, n_mels=126) # [126,126]
            spec_db=librosa.power_to_db(spec,top_db=80)
            spec_image = np.expand_dims(spec_to_image(spec_db), axis=0)
            self.audio.append(spec_image.tolist())
        self.audio = np.array(self.audio)
    def __len__(self):
        return len(self.audio)
    def __getitem__(self, idx):
        return self.audio[idx], self.labels[idx]

# 30초 ~ 1분정도 소요
dataset = esc50dataset(wav_list, metadata)
features = dataset[:][0]
labels = dataset[:][1]

######## train test split ######## Day4 실습 참고
## test data는 200개 이상 존재해야하며 train, val data와 중복되서는 안됩니다

train_size = 0.7
val_size =  0.5

# make train set
split_id = int(len(features) * train_size) 
train_x, remain_x = features[:split_id], features[split_id:] 
train_y, remain_y = labels[:split_id], labels[split_id:]

# make val and test set
split_val_id = int(len(remain_x) * val_size) 
val_x, test_x = remain_x[:split_val_id], remain_x[split_val_id:]
val_y, test_y = remain_y[:split_val_id], remain_y[split_val_id:]

# define batch size # RuntimeError: CUDA out of memory 에러 출력 시 batch_size 낮추고 실행
batch_size = 64

# create tensor datasets
train_set = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))
valid_set = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))
test_set = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))

# create dataloaders
train_loader = DataLoader(train_set, shuffle = True, batch_size = batch_size)
val_loader = DataLoader(valid_set, shuffle = True, batch_size = batch_size)
test_loader = DataLoader(test_set, shuffle = True, batch_size = batch_size)

# Model Hyperparameter
input_size = 128
num_classes = 50
learning_rate = 0.001
num_epochs = 20
sequence_length = 126

######## Model ########

class CRNN(nn.Module):
    def __init__(self, input_size, num_classes) :
        super(CRNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels = 1,
                      out_channels = 8,
                      kernel_size = 3,
                      stride = 1,
                      padding = 2),
            nn.BatchNorm2d(num_features = 8),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        
        self.layer2 = nn.Sequential(
            nn.Conv2d(in_channels = 8,
                      out_channels = 16,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.layer3 = nn.Sequential(
            nn.Conv2d(in_channels = 16,
                      out_channels = 32,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(in_channels = 32,
                      out_channels = 64,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.layer5 = nn.Sequential(
            nn.Conv2d(in_channels = 64,
                      out_channels = 128,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.layer6 = nn.Sequential(
            nn.Conv2d(in_channels = 128,
                      out_channels = 256,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.layer7 = nn.Sequential(
            nn.Conv2d(in_channels = 256,
                      out_channels = 512,
                      kernel_size = 3,
                      stride = 1, 
                      padding = 1),
            nn.BatchNorm2d(num_features = 512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size = 2)
        )
        self.gru = nn.GRU(input_size, hidden_size = 256 , num_layers = 2 , batch_first = True) 
        self.fc = nn.Linear(in_features = 256, out_features = num_classes)

    def forward(self, x):
        x = x.float()
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        x = self.layer5(x)
        x = self.layer6(x)
        x = self.layer7(x)
        x = x.reshape(x.size(0), -1, input_size)
        out, _  = self.gru(x) # output: tensor [batch_size, seq_length, hidden_size]
        out = self.fc(out[:, -1,:])

        return out

######## Criterion & Optimizer ########

model = CRNN(input_size, num_classes).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

######## Train ########

# Train Loop
tr_loss = []
tr_acc = []
v_loss = []
v_acc = []

from tqdm import tqdm

best_valid_loss = torch.inf
best_epoch = 0
model = model.to(device)
epochloop = tqdm(range(num_epochs), position=0, desc='Training', leave=True)
for epoch in epochloop:
    model.train()
    train_loss = 0
    train_acc = 0

    ## Train
    for idx, (text, label) in enumerate(train_loader):
        epochloop.set_postfix_str(f'Training batch {idx}/{len(train_loader)}') # visualize
        text, label = text.to(device), label.to(device)

        out = model(text).squeeze(1)
        # acc
        _, pred = torch.max(out.data, 1)

        train_acc += (pred == label).sum()

        # loss
        optimizer.zero_grad()
        loss = criterion(out.squeeze(), label)
        train_loss += loss.item()
        loss.backward()
        optimizer.step()   

    ## Validation
    model.eval()
    val_loss = 0
    val_acc = 0

    with torch.no_grad():
        for idx, (text, label) in enumerate(val_loader):
            epochloop.set_postfix_str(f'Validation batch {idx}/{len(val_loader)}')
            text, label = text.to(device), label.to(device)

            # forward pass
            out = model(text)
            # acc
            _, pred = torch.max(out.data, 1)

            val_acc += (pred==label).sum()

            # loss
            loss = criterion(out.squeeze(), label)
            val_loss += loss.item()
    model.train()
    # save model if validation loss decrease
    if val_loss / len(valid_set) <= best_valid_loss :
        best_valid_loss = val_loss / len(val_loader)
        best_epoch = epoch
        torch.save(model.state_dict(), "LSTM_epoch_{}.pth".format(epoch))

    # print epoch loss & accuracy
    print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss / len(train_loader):.3f} Train Acc: {train_acc / len(train_set) * 100}% | Val Loss: {val_loss / len(val_loader):.3f} Val Acc: {val_acc / len(valid_set) * 100}%')
    tr_loss.append(train_loss / len(train_loader))
    tr_acc.append(train_acc.cpu().numpy() / len(train_set) * 100)
    v_loss.append(val_loss / len(val_loader))
    v_acc.append(val_acc.cpu().numpy() / len(valid_set) * 100)

######## Test ########
test_model = CRNN(input_size, num_classes).to(device)

torch.save(model.state_dict(),"model.pth") 

test_model.load_state_dict(torch.load('model.pth'))
acc_list = []
test_model.eval()

# metrics
test_acc = 0
with torch.no_grad():
    for audio, label in test_loader:
        audio, label = audio.to(device), label.to(device)

        # forward pass
        out = test_model(audio)

        # acc
        _, pred = torch.max(out, 1)
        test_acc += (pred==label).sum()
        
    print(f'Accuracy: {test_acc.cpu().numpy()/len(test_set) * 100}%')